{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy Customers Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description:\n",
    "\n",
    "Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers <br/>\n",
    "X1 = my order was delivered on time <br/>\n",
    "X2 = contents of my order was as I expected <br/>\n",
    "X3 = I ordered everything I wanted to order <br/>\n",
    "X4 = I paid a good price for my order <br/>\n",
    "X5 = I am satisfied with my courier <br/>\n",
    "X6 = the app makes ordering easy for me <br/>\n",
    "\n",
    "Attributes X1 to X6 indicate the responses for each question and have values from 1 to 5 where the smaller number indicates less and the higher number indicates more towards the answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful libraries\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# EDA\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model, hyperparameter search and scoring\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Y  X1  X2  X3  X4  X5  X6\n",
      "0    0   3   3   3   4   2   4\n",
      "1    0   3   2   3   5   4   3\n",
      "2    1   5   3   3   3   3   5\n",
      "3    0   5   4   3   3   3   5\n",
      "4    0   5   4   3   3   3   5\n",
      "..  ..  ..  ..  ..  ..  ..  ..\n",
      "121  1   5   2   3   4   4   3\n",
      "122  1   5   2   3   4   2   5\n",
      "123  1   5   3   3   4   4   5\n",
      "124  0   4   3   3   4   4   5\n",
      "125  0   5   3   2   5   5   5\n",
      "\n",
      "[126 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3510ae1db1e4ea1b41ec9ef50d45349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79d752f8f114baaba6ba47884b08905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7eae99436644d4d9a2af4e3fc6d4ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1e96ac72ba44068cace9fa9ff9ca67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(\"Data/ACME-HappinessSurvey2020.csv\")\n",
    "print(data)\n",
    "\n",
    "# perform EDA on the whole dataset to understand the data \n",
    "profile = ProfileReport(data)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     p-value\n",
      "X1  0.001486\n",
      "X2  0.787313\n",
      "X3  0.091807\n",
      "X4  0.473623\n",
      "X5  0.011488\n",
      "X6  0.060568\n",
      "\n",
      "Top 6 Selected Features: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6']\n"
     ]
    }
   ],
   "source": [
    "# create two dataset: one with the target variable and one with the features\n",
    "Y = data.iloc[:, 0]\n",
    "X = data.drop('Y', axis=1)\n",
    "\n",
    "# define feature selection\n",
    "k = 6\n",
    "fs = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "# apply feature selection\n",
    "X_selected = fs.fit_transform(X, Y)\n",
    "X_selected = pd.DataFrame(X_selected)\n",
    "\n",
    "# print the pvalue of the features and the selected features\n",
    "pvalues = pd.DataFrame(fs.pvalues_, list(X.columns))\n",
    "pvalues.columns = ['p-value']\n",
    "print(pvalues)\n",
    "\n",
    "selectedFeatures = list(X.columns[ sorted(np.argsort(fs.pvalues_)[:k]) ])\n",
    "print(f'\\nTop {k} Selected Features: {selectedFeatures}') \n",
    "\n",
    "# take the indices of the selected features with: sorted(np.argsort(fs.pvalues_)[:-(k - 2)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None...\n",
       "       0.32, 0.34, 0.36, 0.38, 0.4 , 0.42, 0.44, 0.46, 0.48]),\n",
       "                                        'gamma': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                                        'learning_rate': [0.001, 0.01, 0.1, 0.2,\n",
       "                                                          0.3],\n",
       "                                        'max_depth': array([ 5,  8, 11, 14, 17, 20, 23, 26, 29]),\n",
       "                                        'min_child_weight': array([ 1,  4,  7, 10, 13, 16, 19]),\n",
       "                                        'n_estimators': [50, 100, 200, 300,\n",
       "                                                         400],\n",
       "                                        'subsample': array([0.2 , 0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 ,\n",
       "       0.42, 0.44, 0.46, 0.48])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dataset into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selectedFeatures], Y, test_size=0.30, random_state=25)\n",
    "\n",
    "# search space for our parameters\n",
    "\n",
    "params = { 'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.2, 0.5, 0.02),\n",
    "           'min_child_weight': np.arange(1, 20, 3),\n",
    "           'gamma': np.arange(1, 20, 1),\n",
    "           'max_depth': np.arange(5, 30, 3),\n",
    "           'colsample_bytree': np.arange(0.1, 0.5, 0.02),\n",
    "           'n_estimators': [50, 100, 200, 300, 400]}\n",
    "\n",
    "# create model\n",
    "xgbr = XGBClassifier(objective= 'binary:logistic',\n",
    "                     use_label_encoder = False,\n",
    "                     verbosity = 0)\n",
    "\n",
    "# create randomized search\n",
    "clf = RandomizedSearchCV(estimator=xgbr,\n",
    "                         param_distributions=params,\n",
    "                         #scoring = 'accuracy',\n",
    "                         n_iter=80,\n",
    "                         verbose=1)\n",
    "\n",
    "# fit model to find best hyperparameters\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.1</td>\n",
       "      <td>29</td>\n",
       "      <td>300</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.669281</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11</td>\n",
       "      <td>300</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17</td>\n",
       "      <td>300</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>300</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>400</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23</td>\n",
       "      <td>400</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.001</td>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29</td>\n",
       "      <td>300</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score param_learning_rate param_max_depth  \\\n",
       "59                1         0.702614                 0.1              29   \n",
       "8                 2         0.669281                 0.3              11   \n",
       "32                3         0.647059                 0.1              17   \n",
       "13                4         0.601961                 0.3               8   \n",
       "11                5         0.580392                 0.2              29   \n",
       "31                6         0.568627                0.01              11   \n",
       "34                6         0.568627                 0.3              23   \n",
       "37                6         0.568627               0.001              14   \n",
       "38                6         0.568627                 0.3              29   \n",
       "78                6         0.568627                 0.1               5   \n",
       "\n",
       "   param_n_estimators param_subsample param_colsample_bytree  \\\n",
       "59                300            0.44                   0.36   \n",
       "8                 300            0.36                    0.2   \n",
       "32                300            0.44                    0.3   \n",
       "13                200            0.46                    0.3   \n",
       "11                300            0.32                   0.18   \n",
       "31                400             0.4                   0.34   \n",
       "34                400             0.2                   0.32   \n",
       "37                300            0.34                   0.46   \n",
       "38                300            0.38                   0.26   \n",
       "78                300            0.34                   0.44   \n",
       "\n",
       "   param_min_child_weight param_gamma  \n",
       "59                      1           5  \n",
       "8                       1           1  \n",
       "32                      1           7  \n",
       "13                      1          13  \n",
       "11                      1           9  \n",
       "31                      7          15  \n",
       "34                      1           6  \n",
       "37                      7           1  \n",
       "38                      7          10  \n",
       "78                      4           1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_results = pd.DataFrame(clf.cv_results_)\n",
    "df_cv_results = df_cv_results[[\"rank_test_score\",\"mean_test_score\",\n",
    "                               \"param_learning_rate\", \n",
    "                               \"param_max_depth\", \n",
    "                               \"param_n_estimators\", \n",
    "                               \"param_subsample\", \n",
    "                               \"param_colsample_bytree\", \n",
    "                               \"param_min_child_weight\", \n",
    "                               \"param_gamma\"]]\n",
    "df_cv_results.sort_values(by='rank_test_score', inplace=True)\n",
    "df_cv_results[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.36,\n",
       "              enable_categorical=False, gamma=5, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=29,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=300, n_jobs=12, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.44, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost_fin = XGBClassifier(objective= 'binary:logistic',\n",
    "\n",
    "                                  learning_rate=0.1,\n",
    "                                  max_depth=29,\n",
    "                                  n_estimators=300,\n",
    "                                  subsample=0.44,\n",
    "                                  colsample_bytree=0.36,\n",
    "                                  min_child_weight=1,\n",
    "                                  gamma = 5,\n",
    "\n",
    "                                  verbosity=0,\n",
    "                                  use_label_encoder=False)\n",
    "\n",
    "\n",
    "\n",
    "model_xgboost_fin.fit(X_train,\n",
    "                      y_train,\n",
    "                      verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 1 0 0 1 1]\n",
      "True Positive(TP)  =  37\n",
      "False Positive(FP) =  12\n",
      "True Negative(TN)  =  26\n",
      "False Negative(FN) =  13\n",
      "Train Accuracy = 0.716\n",
      "\n",
      "[1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1\n",
      " 0]\n",
      "True Positive(TP)  =  8\n",
      "False Positive(FP) =  8\n",
      "True Negative(TN)  =  11\n",
      "False Negative(FN) =  11\n",
      "Test Accuracy = 0.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_test_scores(model, mode, X, y):\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "\n",
    "    TN, FP, FN, TP = confusion_matrix(y, predictions).ravel()\n",
    "\n",
    "    print('True Positive(TP)  = ', TP)\n",
    "    print('False Positive(FP) = ', FP)\n",
    "    print('True Negative(TN)  = ', TN)\n",
    "    print('False Negative(FN) = ', FN)\n",
    "\n",
    "    accuracy =  (TP+TN) /(TP+FP+TN+FN)\n",
    "\n",
    "    print(f'{mode} Accuracy = {accuracy:.3f}\\n')\n",
    "\n",
    "train_test_scores(model_xgboost_fin, 'Train', X_train, y_train)\n",
    "train_test_scores(model_xgboost_fin, 'Test', X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable  Importance\n",
       "0       X1         1.0\n",
       "1       X2         0.0\n",
       "2       X3         0.0\n",
       "3       X4         0.0\n",
       "4       X5         0.0\n",
       "5       X6         0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_var_imp = pd.DataFrame({\"Variable\": selectedFeatures,\n",
    "                           \"Importance\": model_xgboost_fin.feature_importances_}) \\\n",
    "                        .sort_values(by='Importance', ascending=False)\n",
    "df_var_imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d5e04cb478149a6af31ca6f5e2d4f1ae295728d207584bbfabb5053485e7967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
